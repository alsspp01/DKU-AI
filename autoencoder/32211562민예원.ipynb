{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea53d44-c321-49ab-b76e-85008fa19eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e153f356-465e-4a85-b11a-81a11971008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./creditcard.csv')\n",
    "data.drop(['Time', 'Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40047cc-010e-4c82-af1a-6fb1cf17d482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284807.000000\n",
       "mean          0.001727\n",
       "std           0.041527\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           0.000000\n",
       "max           1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "min = data.min()\n",
    "max = data.max()\n",
    "data = (data - min) / (max - min)\n",
    "data.Class.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f515f8-29b9-4b82-b8db-137c72275633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_data = data.iloc[:,:-1]\n",
    "y_data = data.Class\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9e54ad-0d85-40bb-9e26-8ba99e6113a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76551</th>\n",
       "      <td>0.977581</td>\n",
       "      <td>0.744511</td>\n",
       "      <td>0.826291</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.767214</td>\n",
       "      <td>0.302058</td>\n",
       "      <td>0.253941</td>\n",
       "      <td>0.795433</td>\n",
       "      <td>0.417551</td>\n",
       "      <td>0.535243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563789</td>\n",
       "      <td>0.582449</td>\n",
       "      <td>0.561717</td>\n",
       "      <td>0.509246</td>\n",
       "      <td>0.661947</td>\n",
       "      <td>0.520236</td>\n",
       "      <td>0.602263</td>\n",
       "      <td>0.417096</td>\n",
       "      <td>0.417261</td>\n",
       "      <td>0.314316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56950</th>\n",
       "      <td>0.930311</td>\n",
       "      <td>0.786395</td>\n",
       "      <td>0.853762</td>\n",
       "      <td>0.280112</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.265650</td>\n",
       "      <td>0.271645</td>\n",
       "      <td>0.781936</td>\n",
       "      <td>0.456641</td>\n",
       "      <td>0.542705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643278</td>\n",
       "      <td>0.582927</td>\n",
       "      <td>0.556258</td>\n",
       "      <td>0.476487</td>\n",
       "      <td>0.663408</td>\n",
       "      <td>0.333352</td>\n",
       "      <td>0.561109</td>\n",
       "      <td>0.305680</td>\n",
       "      <td>0.396601</td>\n",
       "      <td>0.303003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36277</th>\n",
       "      <td>0.957147</td>\n",
       "      <td>0.776647</td>\n",
       "      <td>0.861656</td>\n",
       "      <td>0.315987</td>\n",
       "      <td>0.766969</td>\n",
       "      <td>0.261597</td>\n",
       "      <td>0.270743</td>\n",
       "      <td>0.783065</td>\n",
       "      <td>0.438723</td>\n",
       "      <td>0.515761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719480</td>\n",
       "      <td>0.582183</td>\n",
       "      <td>0.562931</td>\n",
       "      <td>0.536425</td>\n",
       "      <td>0.661729</td>\n",
       "      <td>0.430704</td>\n",
       "      <td>0.568947</td>\n",
       "      <td>0.400633</td>\n",
       "      <td>0.416622</td>\n",
       "      <td>0.311442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122460</th>\n",
       "      <td>0.874678</td>\n",
       "      <td>0.720445</td>\n",
       "      <td>0.847127</td>\n",
       "      <td>0.339339</td>\n",
       "      <td>0.794375</td>\n",
       "      <td>0.256339</td>\n",
       "      <td>0.250846</td>\n",
       "      <td>0.794642</td>\n",
       "      <td>0.447070</td>\n",
       "      <td>0.511484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516320</td>\n",
       "      <td>0.577307</td>\n",
       "      <td>0.563933</td>\n",
       "      <td>0.520913</td>\n",
       "      <td>0.636177</td>\n",
       "      <td>0.229423</td>\n",
       "      <td>0.568805</td>\n",
       "      <td>0.404795</td>\n",
       "      <td>0.426322</td>\n",
       "      <td>0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100456</th>\n",
       "      <td>0.977462</td>\n",
       "      <td>0.762477</td>\n",
       "      <td>0.858773</td>\n",
       "      <td>0.260635</td>\n",
       "      <td>0.757152</td>\n",
       "      <td>0.261159</td>\n",
       "      <td>0.260828</td>\n",
       "      <td>0.787446</td>\n",
       "      <td>0.495665</td>\n",
       "      <td>0.502830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616004</td>\n",
       "      <td>0.579658</td>\n",
       "      <td>0.558860</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.463897</td>\n",
       "      <td>0.581745</td>\n",
       "      <td>0.574383</td>\n",
       "      <td>0.415759</td>\n",
       "      <td>0.313289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90510</th>\n",
       "      <td>0.978969</td>\n",
       "      <td>0.769211</td>\n",
       "      <td>0.836705</td>\n",
       "      <td>0.296013</td>\n",
       "      <td>0.769270</td>\n",
       "      <td>0.271212</td>\n",
       "      <td>0.265160</td>\n",
       "      <td>0.787284</td>\n",
       "      <td>0.463923</td>\n",
       "      <td>0.509421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591422</td>\n",
       "      <td>0.578967</td>\n",
       "      <td>0.559469</td>\n",
       "      <td>0.504829</td>\n",
       "      <td>0.662170</td>\n",
       "      <td>0.230395</td>\n",
       "      <td>0.623293</td>\n",
       "      <td>0.383251</td>\n",
       "      <td>0.417236</td>\n",
       "      <td>0.312999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39353</th>\n",
       "      <td>0.973059</td>\n",
       "      <td>0.757115</td>\n",
       "      <td>0.855740</td>\n",
       "      <td>0.269988</td>\n",
       "      <td>0.755959</td>\n",
       "      <td>0.262135</td>\n",
       "      <td>0.261458</td>\n",
       "      <td>0.787782</td>\n",
       "      <td>0.510943</td>\n",
       "      <td>0.498020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559372</td>\n",
       "      <td>0.581015</td>\n",
       "      <td>0.559602</td>\n",
       "      <td>0.489468</td>\n",
       "      <td>0.666079</td>\n",
       "      <td>0.443112</td>\n",
       "      <td>0.573145</td>\n",
       "      <td>0.579268</td>\n",
       "      <td>0.415516</td>\n",
       "      <td>0.313850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25056</th>\n",
       "      <td>0.981228</td>\n",
       "      <td>0.754549</td>\n",
       "      <td>0.842115</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>0.756268</td>\n",
       "      <td>0.257208</td>\n",
       "      <td>0.260102</td>\n",
       "      <td>0.783922</td>\n",
       "      <td>0.398160</td>\n",
       "      <td>0.537310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514600</td>\n",
       "      <td>0.577753</td>\n",
       "      <td>0.559143</td>\n",
       "      <td>0.502566</td>\n",
       "      <td>0.665439</td>\n",
       "      <td>0.390584</td>\n",
       "      <td>0.594914</td>\n",
       "      <td>0.396383</td>\n",
       "      <td>0.417038</td>\n",
       "      <td>0.313689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93161</th>\n",
       "      <td>0.934777</td>\n",
       "      <td>0.762249</td>\n",
       "      <td>0.883312</td>\n",
       "      <td>0.269922</td>\n",
       "      <td>0.758004</td>\n",
       "      <td>0.264234</td>\n",
       "      <td>0.271916</td>\n",
       "      <td>0.785362</td>\n",
       "      <td>0.471887</td>\n",
       "      <td>0.493037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459705</td>\n",
       "      <td>0.586607</td>\n",
       "      <td>0.568383</td>\n",
       "      <td>0.541758</td>\n",
       "      <td>0.670869</td>\n",
       "      <td>0.423962</td>\n",
       "      <td>0.601134</td>\n",
       "      <td>0.369082</td>\n",
       "      <td>0.412901</td>\n",
       "      <td>0.310794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79750</th>\n",
       "      <td>0.979029</td>\n",
       "      <td>0.768304</td>\n",
       "      <td>0.837114</td>\n",
       "      <td>0.271115</td>\n",
       "      <td>0.766433</td>\n",
       "      <td>0.262699</td>\n",
       "      <td>0.265699</td>\n",
       "      <td>0.785763</td>\n",
       "      <td>0.459735</td>\n",
       "      <td>0.508922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577803</td>\n",
       "      <td>0.578831</td>\n",
       "      <td>0.561310</td>\n",
       "      <td>0.516469</td>\n",
       "      <td>0.663467</td>\n",
       "      <td>0.348682</td>\n",
       "      <td>0.612122</td>\n",
       "      <td>0.521445</td>\n",
       "      <td>0.415787</td>\n",
       "      <td>0.312794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71079 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "76551   0.977581  0.744511  0.826291  0.154900  0.767214  0.302058  0.253941   \n",
       "56950   0.930311  0.786395  0.853762  0.280112  0.769565  0.265650  0.271645   \n",
       "36277   0.957147  0.776647  0.861656  0.315987  0.766969  0.261597  0.270743   \n",
       "122460  0.874678  0.720445  0.847127  0.339339  0.794375  0.256339  0.250846   \n",
       "100456  0.977462  0.762477  0.858773  0.260635  0.757152  0.261159  0.260828   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "90510   0.978969  0.769211  0.836705  0.296013  0.769270  0.271212  0.265160   \n",
       "39353   0.973059  0.757115  0.855740  0.269988  0.755959  0.262135  0.261458   \n",
       "25056   0.981228  0.754549  0.842115  0.193216  0.756268  0.257208  0.260102   \n",
       "93161   0.934777  0.762249  0.883312  0.269922  0.758004  0.264234  0.271916   \n",
       "79750   0.979029  0.768304  0.837114  0.271115  0.766433  0.262699  0.265699   \n",
       "\n",
       "              V8        V9       V10  ...       V19       V20       V21  \\\n",
       "76551   0.795433  0.417551  0.535243  ...  0.563789  0.582449  0.561717   \n",
       "56950   0.781936  0.456641  0.542705  ...  0.643278  0.582927  0.556258   \n",
       "36277   0.783065  0.438723  0.515761  ...  0.719480  0.582183  0.562931   \n",
       "122460  0.794642  0.447070  0.511484  ...  0.516320  0.577307  0.563933   \n",
       "100456  0.787446  0.495665  0.502830  ...  0.616004  0.579658  0.558860   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "90510   0.787284  0.463923  0.509421  ...  0.591422  0.578967  0.559469   \n",
       "39353   0.787782  0.510943  0.498020  ...  0.559372  0.581015  0.559602   \n",
       "25056   0.783922  0.398160  0.537310  ...  0.514600  0.577753  0.559143   \n",
       "93161   0.785362  0.471887  0.493037  ...  0.459705  0.586607  0.568383   \n",
       "79750   0.785763  0.459735  0.508922  ...  0.577803  0.578831  0.561310   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \n",
       "76551   0.509246  0.661947  0.520236  0.602263  0.417096  0.417261  0.314316  \n",
       "56950   0.476487  0.663408  0.333352  0.561109  0.305680  0.396601  0.303003  \n",
       "36277   0.536425  0.661729  0.430704  0.568947  0.400633  0.416622  0.311442  \n",
       "122460  0.520913  0.636177  0.229423  0.568805  0.404795  0.426322  0.279597  \n",
       "100456  0.496899  0.666666  0.463897  0.581745  0.574383  0.415759  0.313289  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "90510   0.504829  0.662170  0.230395  0.623293  0.383251  0.417236  0.312999  \n",
       "39353   0.489468  0.666079  0.443112  0.573145  0.579268  0.415516  0.313850  \n",
       "25056   0.502566  0.665439  0.390584  0.594914  0.396383  0.417038  0.313689  \n",
       "93161   0.541758  0.670869  0.423962  0.601134  0.369082  0.412901  0.310794  \n",
       "79750   0.516469  0.663467  0.348682  0.612122  0.521445  0.415787  0.312794  \n",
       "\n",
       "[71079 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[y_test==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1445cafd-e3f3-457a-9a69-661eae0328db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    inputs = keras.Input(shape=(28, ), name=\"thresholds\")\n",
    "    x = layers.Dense(10, activation = \"relu\", name = \"dense_1\")(inputs)\n",
    "    x = layers.Dense(5, activation = \"relu\", name = \"dense_2\")(x)\n",
    "    x = layers.Dense(10, activation = \"relu\", name = \"dense_3\")(x)\n",
    "    outputs = layers.Dense(28, name = \"predictions\")(x)\n",
    "    model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                 loss = tf.keras.losses.mean_absolute_error,\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2f39a8-ae52-47b7-b554-3f1c881a8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9512 - loss: 0.0551 - val_accuracy: 0.9923 - val_loss: 0.0230\n",
      "Epoch 2/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359us/step - accuracy: 0.9920 - loss: 0.0230 - val_accuracy: 0.9923 - val_loss: 0.0229\n",
      "Epoch 3/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9923 - loss: 0.0229 - val_accuracy: 0.9923 - val_loss: 0.0229\n",
      "Epoch 4/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364us/step - accuracy: 0.9921 - loss: 0.0228 - val_accuracy: 0.9923 - val_loss: 0.0228\n",
      "Epoch 5/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367us/step - accuracy: 0.9918 - loss: 0.0228 - val_accuracy: 0.9923 - val_loss: 0.0228\n",
      "Epoch 6/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364us/step - accuracy: 0.9922 - loss: 0.0227 - val_accuracy: 0.9923 - val_loss: 0.0227\n",
      "Epoch 7/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365us/step - accuracy: 0.9923 - loss: 0.0227 - val_accuracy: 0.9923 - val_loss: 0.0226\n",
      "Epoch 8/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366us/step - accuracy: 0.9919 - loss: 0.0226 - val_accuracy: 0.9923 - val_loss: 0.0224\n",
      "Epoch 9/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378us/step - accuracy: 0.9921 - loss: 0.0225 - val_accuracy: 0.9923 - val_loss: 0.0223\n",
      "Epoch 10/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383us/step - accuracy: 0.9924 - loss: 0.0223 - val_accuracy: 0.9923 - val_loss: 0.0221\n",
      "Epoch 11/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9921 - loss: 0.0221 - val_accuracy: 0.9923 - val_loss: 0.0219\n",
      "Epoch 12/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366us/step - accuracy: 0.9921 - loss: 0.0220 - val_accuracy: 0.9923 - val_loss: 0.0220\n",
      "Epoch 13/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 361us/step - accuracy: 0.9923 - loss: 0.0218 - val_accuracy: 0.9923 - val_loss: 0.0218\n",
      "Epoch 14/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366us/step - accuracy: 0.9924 - loss: 0.0218 - val_accuracy: 0.9923 - val_loss: 0.0217\n",
      "Epoch 15/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363us/step - accuracy: 0.9924 - loss: 0.0218 - val_accuracy: 0.9923 - val_loss: 0.0217\n",
      "Epoch 16/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365us/step - accuracy: 0.9922 - loss: 0.0217 - val_accuracy: 0.9923 - val_loss: 0.0214\n",
      "Epoch 17/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365us/step - accuracy: 0.9922 - loss: 0.0212 - val_accuracy: 0.9923 - val_loss: 0.0202\n",
      "Epoch 18/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368us/step - accuracy: 0.9923 - loss: 0.0201 - val_accuracy: 0.9923 - val_loss: 0.0196\n",
      "Epoch 19/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 369us/step - accuracy: 0.9922 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0195\n",
      "Epoch 20/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9921 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 21/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9920 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
      "Epoch 22/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9921 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
      "Epoch 23/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9923 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 24/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9922 - loss: 0.0194 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
      "Epoch 25/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9921 - loss: 0.0194 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 26/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9921 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0195\n",
      "Epoch 27/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9924 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0195\n",
      "Epoch 28/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380us/step - accuracy: 0.9920 - loss: 0.0194 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
      "Epoch 29/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9923 - loss: 0.0194 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
      "Epoch 30/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399us/step - accuracy: 0.9921 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
      "Epoch 31/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362us/step - accuracy: 0.9922 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 32/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363us/step - accuracy: 0.9921 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0194\n",
      "Epoch 33/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363us/step - accuracy: 0.9919 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0195\n",
      "Epoch 34/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 361us/step - accuracy: 0.9918 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0192\n",
      "Epoch 35/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367us/step - accuracy: 0.9919 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 36/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9920 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 37/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386us/step - accuracy: 0.9920 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0192\n",
      "Epoch 38/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363us/step - accuracy: 0.9919 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 39/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386us/step - accuracy: 0.9924 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0192\n",
      "Epoch 40/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9924 - loss: 0.0193 - val_accuracy: 0.9923 - val_loss: 0.0192\n",
      "Epoch 41/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378us/step - accuracy: 0.9922 - loss: 0.0192 - val_accuracy: 0.9923 - val_loss: 0.0192\n",
      "Epoch 42/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9917 - loss: 0.0192 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 43/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9920 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 44/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9919 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 45/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9922 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 46/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9919 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 47/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379us/step - accuracy: 0.9920 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 48/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9917 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 49/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 379us/step - accuracy: 0.9918 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0192\n",
      "Epoch 50/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9923 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 51/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9920 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 52/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9923 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 53/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376us/step - accuracy: 0.9920 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 54/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 376us/step - accuracy: 0.9923 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 55/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9922 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 56/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9923 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 57/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9918 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 58/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9924 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0193\n",
      "Epoch 59/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 375us/step - accuracy: 0.9920 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 60/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9921 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 61/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386us/step - accuracy: 0.9921 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0189\n",
      "Epoch 62/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9923 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 63/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9921 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0192\n",
      "Epoch 64/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368us/step - accuracy: 0.9925 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 65/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9925 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 66/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 367us/step - accuracy: 0.9918 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 67/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9922 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 68/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9919 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 69/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9920 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 70/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9925 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 71/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9924 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 72/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9921 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 73/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9923 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 74/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9921 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 75/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9923 - loss: 0.0191 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 76/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9924 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 77/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9918 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0191\n",
      "Epoch 78/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380us/step - accuracy: 0.9923 - loss: 0.0190 - val_accuracy: 0.9923 - val_loss: 0.0189\n",
      "Epoch 79/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9925 - loss: 0.0189 - val_accuracy: 0.9923 - val_loss: 0.0189\n",
      "Epoch 80/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9922 - loss: 0.0189 - val_accuracy: 0.9923 - val_loss: 0.0189\n",
      "Epoch 81/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383us/step - accuracy: 0.9918 - loss: 0.0189 - val_accuracy: 0.9923 - val_loss: 0.0190\n",
      "Epoch 82/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 373us/step - accuracy: 0.9922 - loss: 0.0189 - val_accuracy: 0.9923 - val_loss: 0.0189\n",
      "Epoch 83/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9923 - loss: 0.0189 - val_accuracy: 0.9923 - val_loss: 0.0189\n",
      "Epoch 84/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9922 - loss: 0.0189 - val_accuracy: 0.9923 - val_loss: 0.0187\n",
      "Epoch 85/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 377us/step - accuracy: 0.9924 - loss: 0.0188 - val_accuracy: 0.9923 - val_loss: 0.0188\n",
      "Epoch 86/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9918 - loss: 0.0187 - val_accuracy: 0.9923 - val_loss: 0.0187\n",
      "Epoch 87/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9920 - loss: 0.0187 - val_accuracy: 0.9923 - val_loss: 0.0186\n",
      "Epoch 88/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9921 - loss: 0.0186 - val_accuracy: 0.9923 - val_loss: 0.0185\n",
      "Epoch 89/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9919 - loss: 0.0186 - val_accuracy: 0.9923 - val_loss: 0.0177\n",
      "Epoch 90/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9920 - loss: 0.0176 - val_accuracy: 0.9923 - val_loss: 0.0172\n",
      "Epoch 91/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9920 - loss: 0.0172 - val_accuracy: 0.9923 - val_loss: 0.0171\n",
      "Epoch 92/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 374us/step - accuracy: 0.9922 - loss: 0.0171 - val_accuracy: 0.9923 - val_loss: 0.0170\n",
      "Epoch 93/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9923 - loss: 0.0170 - val_accuracy: 0.9923 - val_loss: 0.0168\n",
      "Epoch 94/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9923 - loss: 0.0169 - val_accuracy: 0.9923 - val_loss: 0.0169\n",
      "Epoch 95/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 370us/step - accuracy: 0.9916 - loss: 0.0169 - val_accuracy: 0.9923 - val_loss: 0.0167\n",
      "Epoch 96/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9922 - loss: 0.0168 - val_accuracy: 0.9923 - val_loss: 0.0167\n",
      "Epoch 97/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9921 - loss: 0.0167 - val_accuracy: 0.9923 - val_loss: 0.0168\n",
      "Epoch 98/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 371us/step - accuracy: 0.9920 - loss: 0.0167 - val_accuracy: 0.9923 - val_loss: 0.0166\n",
      "Epoch 99/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 378us/step - accuracy: 0.9920 - loss: 0.0166 - val_accuracy: 0.9923 - val_loss: 0.0166\n",
      "Epoch 100/100\n",
      "\u001b[1m6664/6664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 372us/step - accuracy: 0.9922 - loss: 0.0165 - val_accuracy: 0.9923 - val_loss: 0.0166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17e37c770>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(x_train[y_train==0], x_train[y_train==0], epochs=100, validation_data=(x_test[y_test==0], x_test[y_test==0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff909a20-0813-4d22-a919-81f03508818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(actual, pred):\n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.square(np.subtract(actual, pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84426598-ae28-4204-b0a2-c9da18772fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2226/2226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191us/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "predictions = pd.DataFrame(model.predict(x_test))\n",
    "\n",
    "normal_mse = []\n",
    "abnormal_mse = []\n",
    "\n",
    "actual_data = pd.DataFrame(x_test[y_test==0])\n",
    "pred_data = predictions[np.array(y_test==0)]\n",
    "\n",
    "for index in range(len(actual_data)):\n",
    "    normal_mse.append(MSE(actual_data.iloc[index, :], pred_data.iloc[index, :]))\n",
    "\n",
    "actual_data = x_test[y_test==1]\n",
    "pred_data = predictions[np.array(y_test==1)]\n",
    "\n",
    "\n",
    "for index in range(len(actual_data)):\n",
    "    abnormal_mse.append(MSE(actual_data.iloc[index, :], pred_data.iloc[index, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6077eb-73fc-4d2f-acb3-7ac84d76c94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whiskers: [array([3.72943558e-04, 2.92459515e-05]), array([0.00114031, 0.00229129]), array([0.00673281, 0.00044129]), array([0.03081879, 0.06628189])]\n",
      "medians: [array([0.00064653, 0.00064653]), array([0.0144996, 0.0144996])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (4, 3)\n",
    "plt.rcParams['font.size'] = 12\n",
    "fig, ax = plt.subplots()\n",
    "box = ax.boxplot([normal_mse, abnormal_mse])\n",
    "ax.set_ylim(0, 0.03)\n",
    "ax.set_xlabel('Data Type')\n",
    "ax.set_ylabel('error(MSE)')\n",
    "\n",
    "whiskers = [item.get_ydata() for item in box['whiskers']]\n",
    "medians = [item.get_ydata() for item in box['medians']]\n",
    "\n",
    "print('whiskers:', whiskers)\n",
    "print('medians:', medians)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f294a4c-973d-4062-bf39-f58fe64e5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = pd.Series(normal_mse).describe()['75%']\n",
    "flag = []\n",
    "for error in normal_mse + abnormal_mse:\n",
    "    if error > threshold:\n",
    "        flag.append(1)\n",
    "    else:\n",
    "        flag.append(0)\n",
    "y_test = np.array(y_test)\n",
    "flag = np.array(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0014d1-ee86-4161-bf3d-0ea4781aa403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.0013976631072846202\n",
      "Recall:  0.2032520325203252\n",
      "F1 Score:  0.00277623542476402\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "precision = sklearn.metrics.precision_score(y_test, flag)\n",
    "recall = sklearn.metrics.recall_score(y_test, flag)\n",
    "f1score = sklearn.metrics.f1_score(y_test, flag)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1 Score: ', f1score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
